import torch
import matplotlib.pyplot as plt
import numpy as np
from f5.f5tts import F5TTSService
from f5_tts.infer.utils_infer import infer_process, load_vocoder
from adapter.adapter import EnhancedEmbeddingAdapter
from transformers import AutoModelForCausalLM, AutoTokenizer
import seaborn as sns
from pathlib import Path
from f5.ogf5tts import OGF5TTSService
import torchaudio
import torch.nn.functional as F

DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')

def load_models():
    # Load vocoder once and share it
    vocoder = load_vocoder(vocoder_name="vocos", is_local=False)
    
    # Load F5-TTS with shared vocoder
    f5_service = F5TTSService("weights", "Dobby", vocoder=vocoder)
    ogf5_service = OGF5TTSService("weights", "Bob", vocoder=vocoder)
    
    # Load and configure LLaMA model and tokenizer
    tokenizer = AutoTokenizer.from_pretrained("meta-llama/Llama-3.2-3b")
    tokenizer.pad_token = tokenizer.eos_token
    
    llama_model = AutoModelForCausalLM.from_pretrained("meta-llama/Llama-3.2-3b").to(DEVICE)
    llama_model.config.pad_token_id = tokenizer.pad_token_id
    
    # Load adapter
    adapter = EnhancedEmbeddingAdapter().to(DEVICE)
    checkpoint = torch.load("checkpoints/adapter_best.pt")
    adapter.load_state_dict(checkpoint['model_state_dict'])
    adapter.eval()
    
    return f5_service, ogf5_service, llama_model, tokenizer, adapter

def generate_mel_specs(text, f5_service, ogf5_service, llama_model, tokenizer, adapter):
    # First get LLaMA to generate content
    inputs = tokenizer(text, return_tensors="pt", padding=True).to(DEVICE)
    input_length = inputs.input_ids.shape[1]  # Length of input sequence
    
    with torch.no_grad():
        # Generate from LLaMA and get both ids and hidden states
        outputs = llama_model.generate(
            inputs.input_ids,
            max_length=100,
            num_return_sequences=1,
            pad_token_id=tokenizer.pad_token_id,
            eos_token_id=tokenizer.eos_token_id,
            output_hidden_states=True,
            return_dict_in_generate=True
        )
        
        # Get the generated text for old architecture
        decoded_text = tokenizer.decode(outputs.sequences[0], skip_special_tokens=True)
        print(f"\nGenerated text: {decoded_text}")
        
        # Get the embeddings from generation for adapter
        generated_outputs = llama_model(outputs.sequences, output_hidden_states=True)
        llama_embeddings = generated_outputs.hidden_states[-1]  # Last layer, all tokens
        # Only keep embeddings from the generated tokens (exclude input)
        llama_embeddings = llama_embeddings[:, input_length:, :]
        print(f"LLaMA embeddings shape: {llama_embeddings.shape}")
        
        # Get reference audio length from F5-TTS
        ref_audio, sr = torchaudio.load("voice_profiles/Bob/sample_0.wav")
        ref_audio_len = ref_audio.shape[-1] // 256  # hop_length=256
        ref_text = "Hi, I'm recording this sample to create a digital copy of my voice. I want it to sound natural and conversational, just like how I normally speak."
        ref_text_len = len(ref_text.encode("utf-8"))
        
        # Generate adapter mel spectrogram using embeddings from generation
        adapter_mel = adapter(
            llama_embeddings,
            timesteps=torch.zeros(1, device=DEVICE),
            ref_audio_len=ref_audio_len,
            ref_text=ref_text,
            speed=1.0
        )
        print(f"Adapter mel shape: {adapter_mel.shape}")
        print(f"Adapter mel range: [{adapter_mel.min():.3f}, {adapter_mel.max():.3f}]")
    
    # Generate F5-TTS mel spectrogram using generated text
    audio_output, _, f5_mel = infer_process(
        ref_audio="voice_profiles/Bob/sample_0.wav",
        ref_text="Hi, I'm recording this sample to create a digital copy of my voice. I want it to sound natural and conversational, just like how I normally speak.",
        gen_text=decoded_text,  # Use the text generated by LLaMA
        model_obj=ogf5_service.model,
        vocoder=ogf5_service.vocoder,
        mel_spec_type="vocos",
        speed=1.0,
        nfe_step=32,
        cfg_strength=2.0,
        sway_sampling_coef=-1.0,
        device=DEVICE
    )
    f5_mel = torch.from_numpy(f5_mel).unsqueeze(0)
    
    print(f"F5-TTS mel shape: {f5_mel.shape}")
    print(f"F5-TTS mel range: [{f5_mel.min():.3f}, {f5_mel.max():.3f}]")
    
    return f5_mel.cpu().numpy(), adapter_mel.cpu().numpy()

def plot_mel_comparison(f5_mel, adapter_mel, text, save_path=None):
    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 10))
    
    # Plot F5-TTS mel
    im1 = ax1.imshow(f5_mel[0].T, aspect='auto', origin='lower')
    ax1.set_title("F5-TTS Mel Spectrogram")
    plt.colorbar(im1, ax=ax1)
    
    # Plot adapter mel
    im2 = ax2.imshow(adapter_mel[0].T, aspect='auto', origin='lower')
    ax2.set_title("Adapter Mel Spectrogram")
    plt.colorbar(im2, ax=ax2)
    
    plt.suptitle(f'Mel Spectrogram Comparison for:\n"{text}"')
    
    # Add statistics
    stats_text = f"""
    F5-TTS Mel - Shape: {f5_mel.shape}, Range: [{f5_mel.min():.2f}, {f5_mel.max():.2f}]
    Adapter Mel - Shape: {adapter_mel.shape}, Range: [{adapter_mel.min():.2f}, {adapter_mel.max():.2f}]
    """
    fig.text(0.1, 0.01, stats_text, fontsize=10)
    
    plt.tight_layout()
    
    if save_path:
        plt.savefig(save_path)
    plt.show()

def analyze_differences(f5_mel, adapter_mel):
    """Analyze statistical differences between the spectrograms"""
    print("\nMel Spectrogram Analysis:")
    print(f"F5-TTS shape: {f5_mel.shape}")
    print(f"Adapter shape: {adapter_mel.shape}")
    
    # Calculate length ratio
    length_ratio = adapter_mel.shape[2] / f5_mel.shape[2]
    print(f"Length ratio (adapter/f5): {length_ratio:.2f}x")
    
    # Resize adapter mel to match F5-TTS length for comparison
    adapter_mel_resized = F.interpolate(
        torch.from_numpy(adapter_mel).unsqueeze(0),  # Add extra dim for interpolate
        size=(100, f5_mel.shape[2]),
        mode='bilinear',
        align_corners=False
    ).squeeze(0).numpy()
    
    print(f"Resized adapter shape: {adapter_mel_resized.shape}")
    
    # Analyze value ranges and distributions
    print("\nValue Range Analysis:")
    print(f"F5-TTS range: [{f5_mel.min():.3f}, {f5_mel.max():.3f}]")
    print(f"Adapter range: [{adapter_mel.min():.3f}, {adapter_mel.max():.3f}]")
    print(f"Adapter (resized) range: [{adapter_mel_resized.min():.3f}, {adapter_mel_resized.max():.3f}]")
    
    # Calculate percentiles for both
    f5_percentiles = np.percentile(f5_mel, [25, 50, 75])
    adapter_percentiles = np.percentile(adapter_mel_resized, [25, 50, 75])
    print("\nValue Distribution:")
    print(f"F5-TTS percentiles (25, 50, 75): {f5_percentiles}")
    print(f"Adapter percentiles (25, 50, 75): {adapter_percentiles}")
    
    # Calculate differences
    abs_diff = np.abs(f5_mel - adapter_mel_resized)
    mse = np.mean(np.square(f5_mel - adapter_mel_resized))
    correlation = np.corrcoef(f5_mel.flatten(), adapter_mel_resized.flatten())[0, 1]
    
    print("\nDifference Metrics:")
    print(f"Mean Squared Error: {mse:.4f}")
    print(f"Correlation: {correlation:.4f}")
    print(f"Max Absolute Difference: {abs_diff.max():.4f}")
    print(f"Mean Absolute Difference: {abs_diff.mean():.4f}")
    
    # Plot detailed analysis
    fig = plt.figure(figsize=(20, 12))
    
    # Mel spectrograms
    plt.subplot(3, 2, 1)
    plt.imshow(f5_mel[0].T, aspect='auto', origin='lower')
    plt.colorbar()
    plt.title("F5-TTS Mel Spectrogram")
    
    plt.subplot(3, 2, 2)
    plt.imshow(adapter_mel_resized[0].T, aspect='auto', origin='lower')
    plt.colorbar()
    plt.title("Adapter Mel Spectrogram (Resized)")
    
    # Value distributions
    plt.subplot(3, 2, 3)
    plt.hist(f5_mel.flatten(), bins=50, alpha=0.5, label='F5-TTS', density=True)
    plt.hist(adapter_mel_resized.flatten(), bins=50, alpha=0.5, label='Adapter', density=True)
    plt.legend()
    plt.title("Value Distributions")
    
    # Difference analysis
    plt.subplot(3, 2, 4)
    plt.imshow(abs_diff[0].T, aspect='auto', origin='lower')
    plt.colorbar()
    plt.title("Absolute Difference")
    
    # Time-domain analysis
    plt.subplot(3, 2, 5)
    plt.plot(f5_mel[0].mean(axis=0), label='F5-TTS')
    plt.plot(adapter_mel_resized[0].mean(axis=0), label='Adapter')
    plt.legend()
    plt.title("Average Energy Over Time")
    
    # Frequency-domain analysis
    plt.subplot(3, 2, 6)
    plt.plot(f5_mel[0].mean(axis=1), label='F5-TTS')
    plt.plot(adapter_mel_resized[0].mean(axis=1), label='Adapter')
    plt.legend()
    plt.title("Average Energy Across Frequency Bands")
    
    plt.tight_layout()
    plt.show()
    
    # Return key metrics for decision making
    return {
        'length_ratio': length_ratio,
        'mse': mse,
        'correlation': correlation,
        'value_range_diff': (
            abs(f5_mel.max() - adapter_mel_resized.max()),
            abs(f5_mel.min() - adapter_mel_resized.min())
        ),
        'distribution_diff': np.mean(np.abs(f5_percentiles - adapter_percentiles))
    }

def main():
    # Create output directory
    output_dir = Path("mel_analysis")
    output_dir.mkdir(exist_ok=True)
    
    # Load models
    print("Loading models...")
    f5_service, ogf5_service, llama_model, tokenizer, adapter = load_models()
    
    # Test texts
    test_texts = [
        "Hello, how are you today?",
        "This is a test of the mel spectrogram generation.",
        "Dragons soar through cloudy skies.",
    ]
    
    results = []
    for i, text in enumerate(test_texts):
        print(f"\nAnalyzing text {i+1}: {text}")
        
        f5_mel, adapter_mel = generate_mel_specs(
            text, f5_service, ogf5_service, llama_model, tokenizer, adapter
        )
        
        metrics = analyze_differences(f5_mel, adapter_mel)
        results.append(metrics)
    
    # Analyze overall results
    print("\nOverall Analysis:")
    avg_metrics = {
        key: np.mean([r[key] for r in results]) 
        for key in results[0].keys()
    }
    print("\nAverage Metrics:")
    for key, value in avg_metrics.items():
        print(f"{key}: {value:.4f}")
    
    # Make recommendations
    print("\nRecommendations:")
    if avg_metrics['length_ratio'] < 0.8 or avg_metrics['length_ratio'] > 1.2:
        print("- Duration calculation needs adjustment")
    if avg_metrics['correlation'] < 0.5:
        print("- More training needed - low correlation with F5-TTS output")
    if avg_metrics['value_range_diff'][0] > 2.0 or avg_metrics['value_range_diff'][1] > 2.0:
        print("- Value range needs normalization adjustment")
    if avg_metrics['distribution_diff'] > 1.0:
        print("- Distribution mismatch - consider adjusting final layer or normalization")

if __name__ == "__main__":
    main() 